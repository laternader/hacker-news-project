{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hacker News\n",
    "\n",
    "In this project, we are going through data provided by the Hacker News website, started by Y Incubator. Hacker News is popular in the world of technology and start ups that hundreds to thousands of people visit the website to check out the posts. \n",
    "\n",
    "What we are interested in are posts that are either **\"Ask Hn\"** or **\"Show HN\"** and determining what insights we can get from these posts. The data contains approximately 300,000 rows from the original set and was reduced to about 20,000 for the sake of this project. Below are the descriptions of the data:\n",
    "\n",
    "- `id`: the unique identifier from Hacker News for the post\n",
    "- `title`: the title of the post\n",
    "- `url`: the URL that the posts links to, if the post has a URL\n",
    "- `num_points`: the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: the number of comments on the post\n",
    "- `author`: the username of the person who submitted the post\n",
    "- `created_at`: the date and time of the post's submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# Removed & separated the headers from the list of lists\n",
    "headers = hn[0]\n",
    "hn = hn[1:] \n",
    "\n",
    "# View the first 5 rows of data from the CSV file\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Extraction\n",
    "\n",
    "We want to focus on title posts that start with Ask HN or Show HN. In order to find these posts, we'll use the string method `startswith` to determine a boolean as we iterate through each title. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Ask HN, Show HN, and Other posts into separate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask post total: 1744\n",
      "Show post total: 1162\n",
      "Other post total: 17194\n"
     ]
    }
   ],
   "source": [
    "# Initialize 3 empty lists\n",
    "ask_posts, show_posts, other_posts = [], [], []\n",
    "\n",
    "# Iterate through each row and determine the title column to a variable\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    \n",
    "    # Conditional statement: if ask hn, if show hn, else other\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "# We will check the length of the lists\n",
    "print(\"Ask post total:\", len(ask_posts))\n",
    "print('Show post total:', len(show_posts))\n",
    "print('Other post total:', len(other_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the first 5 posts of each list\n",
    "print(ask_posts[:5])\n",
    "print(show_posts[:5])\n",
    "print(other_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data\n",
    "---\n",
    "\n",
    "### Calculating the average amount of comments between Ask HN and Show HN posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comment per ask post: 14.038417431192661\n",
      "Average comment per show post: 10.31669535283993\n",
      "Average comment per other post: 26.8730371059672\n"
     ]
    }
   ],
   "source": [
    "# Find Ask HN post comment average\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "# And then for Show HN post\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "print('Average comment per ask post:', avg_ask_comments)\n",
    "print('Average comment per show post:', avg_show_comments)\n",
    "\n",
    "# Lastly, for giggles, Other posts\n",
    "total_other_comments = 0\n",
    "for post in other_posts:\n",
    "    total_other_comments += int(post[4])\n",
    "avg_other_comments = total_other_comments/len(other_posts)\n",
    "print('Average comment per other post:', avg_other_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discover that the average comment per show post (*10.32*) is less than the average comment per ask post (*14.0*). Although that average comment per other post is significantly higher (*26.9*), that is not the main focus of this project.\n",
    "\n",
    "One observation is that in an \"Ask HN\" post, people who are posting these posts are looking for answers. An answer, comment, or reply, is an expected thing to come out of these posts. There also seems to be a lot of people asking considering the total number of these posts is higher than the \"Show HN\" posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the number of posts and comments in each hour per day\n",
    "\n",
    "We will determine if ask posts created at a certain time are more likely to attract comments for Ask HN posts. We will most likely do the same for Show and Other posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ask HN ##\n",
    "# Create an empty list to contain a list of lists\n",
    "result_list = []\n",
    "\n",
    "# Iterate over ask posts\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = int(post[4])\n",
    "    # Append a list of these two elements into result list\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for item in result_list:\n",
    "    # Extracting the hour from the date\n",
    "    date = dt.datetime.strptime(item[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour = date.strftime(\"%H\")\n",
    "    # Determining counts by hour and comments by hour through conditional if statement\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = item[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts posted by the hour\n",
      " {'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58} \n",
      "\n",
      "Number of comments posted by hour\n",
      " {'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "print('Number of posts posted by the hour\\n', counts_by_hour, '\\n')\n",
    "print('Number of comments posted by hour\\n',comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the dictionaries we created to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour] / counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sort the list of lists and print the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for row in sorted_swap[:5]:\n",
    "    # Used .strptime to return datetime obj, then .strftime to specify the format of the time\n",
    "    hour = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour_formatted = hour.strftime(\"%H:%M\")\n",
    "    # We also rounded the decimals\n",
    "    print(\"{}: {:.2f} average comments per post\".format(hour_formatted,row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our analysis, posting around 3PM will get the most comments/replies to an Ask HN post. There also seems to be a high amount of comments being posted on Ask HN posts around 2AM and 10PM, the 2AM must be due to possibly a comment coming from someone where it is there 3PM over there. The same concept must said about the 10PM time slot because maybe the people who are reply might be people in the same time zone as you, just getting off work and having time to reply before going to bed. \n",
    "\n",
    "If the the algorithm about showing the most newest/relevant posts on Hacking News to the community is very exceptional, then these times of 3PM, 2AM, and 10PM are the best times to post an Ask HN post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the same numbers for Show HN and Others posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show HN ##\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
